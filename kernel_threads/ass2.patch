diff --git a/Makefile b/Makefile
index 3718622..928c5b3 100644
--- a/Makefile
+++ b/Makefile
@@ -143,7 +143,7 @@ tags: $(OBJS) entryother.S _init
 vectors.S: vectors.pl
 	./vectors.pl > vectors.S
 
-ULIB = ulib.o usys.o printf.o umalloc.o
+ULIB = ulib.o usys.o printf.o umalloc.o tournament_tree.o
 
 _%: %.o $(ULIB)
 	$(LD) $(LDFLAGS) -N -e main -Ttext 0 -o $@ $^
@@ -179,6 +179,7 @@ UPROGS=\
 	_sh\
 	_stressfs\
 	_usertests\
+	_sanity\
 	_wc\
 	_zombie\
 
@@ -249,8 +250,8 @@ qemu-nox-gdb: fs.img xv6.img .gdbinit
 
 EXTRA=\
 	mkfs.c ulib.c user.h cat.c echo.c forktest.c grep.c kill.c\
-	ln.c ls.c mkdir.c rm.c stressfs.c usertests.c wc.c zombie.c\
-	printf.c umalloc.c\
+	ln.c ls.c mkdir.c rm.c stressfs.c usertests.c sanity.c wc.c zombie.c\
+	printf.c tournament_tree.c umalloc.c\
 	README dot-bochsrc *.pl toc.* runoff runoff1 runoff.list\
 	.gdbinit.tmpl gdbutil\
 
diff --git a/console.c b/console.c
index a280d2b..fed0cf7 100644
--- a/console.c
+++ b/console.c
@@ -243,7 +243,7 @@ consoleread(struct inode *ip, char *dst, int n)
   acquire(&cons.lock);
   while(n > 0){
     while(input.r == input.w){
-      if(myproc()->killed){
+      if(mykthread()->killed){
         release(&cons.lock);
         ilock(ip);
         return -1;
diff --git a/defs.h b/defs.h
index 82fb982..16a2da5 100644
--- a/defs.h
+++ b/defs.h
@@ -110,6 +110,20 @@ int             growproc(int);
 int             kill(int);
 struct cpu*     mycpu(void);
 struct proc*    myproc();
+struct kthread* mykthread();
+struct spinlock* getptablelock();
+void            deallocallprocessmutexs();
+
+int kthread_create(void (*start_func)(), void* stack);
+int kthread_id();
+void kthread_exit();
+int kthread_join(int thread_id);
+
+int kthread_mutex_alloc();
+int kthread_mutex_dealloc(int mutex_id);
+int kthread_mutex_lock(int mutex_id);
+int kthread_mutex_unlock(int mutex_id);
+
 void            pinit(void);
 void            procdump(void);
 void            scheduler(void) __attribute__((noreturn));
@@ -181,7 +195,7 @@ void            freevm(pde_t*);
 void            inituvm(pde_t*, char*, uint);
 int             loaduvm(pde_t*, char*, struct inode*, uint, uint);
 pde_t*          copyuvm(pde_t*, uint);
-void            switchuvm(struct proc*);
+void            switchuvm(struct proc*, struct kthread*);
 void            switchkvm(void);
 int             copyout(pde_t*, uint, void*, uint);
 void            clearpteu(pde_t *pgdir, char *uva);
diff --git a/exec.c b/exec.c
index b40134f..e8f8c5d 100644
--- a/exec.c
+++ b/exec.c
@@ -6,6 +6,7 @@
 #include "defs.h"
 #include "x86.h"
 #include "elf.h"
+#include "spinlock.h"
 
 int
 exec(char *path, char **argv)
@@ -18,6 +19,64 @@ exec(char *path, char **argv)
   struct proghdr ph;
   pde_t *pgdir, *oldpgdir;
   struct proc *curproc = myproc();
+  struct kthread *curthread = mykthread();
+  struct kthread *t;
+  struct spinlock* ptablelock = getptablelock();
+
+  //our code***
+  acquire(ptablelock);
+redo:
+  for(t = curproc->kthreads; t < &curproc->kthreads[NTHREAD]; t++){
+    if(t->kpid != curthread->kpid && t->state != UNUSED){
+      t->killed = 1;
+      if(t->state == SLEEPING){
+        t->state = RUNNABLE;
+        curproc->runnablethreads++;
+        curproc->pstate = RUNNABLE;
+      }
+    }
+  }
+
+  for(t = curproc->kthreads; t < &curproc->kthreads[NTHREAD]; t++){
+    if((t->kpid == curthread->kpid) || (t->state == UNUSED) || (t->state == ZOMBIE))
+      continue;
+    else{
+      //state is running or runnable (maybe EMBRYO???)
+      sleep(t, ptablelock);
+      goto redo;
+    }
+  }
+  release(ptablelock);
+
+  //dealloc all process mutexts even if mutex is locked
+  deallocallprocessmutexs();
+
+  //at this point only the current thread of the process exist
+  for(t = curproc->kthreads; t < &curproc->kthreads[NTHREAD]; t++){
+    if(t->kpid == curthread->kpid)
+      continue;
+    if(t->state == ZOMBIE){
+      kfree(t->kstack);
+    }
+    t->kstack = 0;
+    t->kpid = 0;
+    t->owner = 0;
+    t->killed = 0;
+    t->name[0] = 0;
+    t->kchan = 0;
+    t->state = UNUSED;
+    t->context = 0;
+    t->tf = 0;
+  }
+
+  for(t = curproc->kthreads; t < &curproc->kthreads[NTHREAD]; t++){
+    if(t->kpid == curthread->kpid)
+      continue;
+    if(t->state != UNUSED){
+      panic("at exec, not all threads are unused\n");
+    }
+  }
+  //end of our code***
 
   begin_op();
 
@@ -91,15 +150,15 @@ exec(char *path, char **argv)
   for(last=s=path; *s; s++)
     if(*s == '/')
       last = s+1;
-  safestrcpy(curproc->name, last, sizeof(curproc->name));
+  safestrcpy(curproc->pname, last, sizeof(curproc->pname));
 
   // Commit to the user image.
   oldpgdir = curproc->pgdir;
   curproc->pgdir = pgdir;
   curproc->sz = sz;
-  curproc->tf->eip = elf.entry;  // main
-  curproc->tf->esp = sp;
-  switchuvm(curproc);
+  curthread->tf->eip = elf.entry;  // main
+  curthread->tf->esp = sp;
+  switchuvm(curproc, curthread);
   freevm(oldpgdir);
   return 0;
 
diff --git a/pipe.c b/pipe.c
index e9abe7f..e230f48 100644
--- a/pipe.c
+++ b/pipe.c
@@ -83,7 +83,7 @@ pipewrite(struct pipe *p, char *addr, int n)
   acquire(&p->lock);
   for(i = 0; i < n; i++){
     while(p->nwrite == p->nread + PIPESIZE){  //DOC: pipewrite-full
-      if(p->readopen == 0 || myproc()->killed){
+      if(p->readopen == 0 || mykthread()->killed){
         release(&p->lock);
         return -1;
       }
@@ -104,7 +104,7 @@ piperead(struct pipe *p, char *addr, int n)
 
   acquire(&p->lock);
   while(p->nread == p->nwrite && p->writeopen){  //DOC: pipe-empty
-    if(myproc()->killed){
+    if(mykthread()->killed){
       release(&p->lock);
       return -1;
     }
diff --git a/proc.c b/proc.c
index 806b1b1..a98bbd1 100644
--- a/proc.c
+++ b/proc.c
@@ -6,6 +6,8 @@
 #include "x86.h"
 #include "proc.h"
 #include "spinlock.h"
+#include "tournament_tree.h"
+#include "kthread.h"
 
 struct {
   struct spinlock lock;
@@ -14,6 +16,14 @@ struct {
 
 static struct proc *initproc;
 
+//our code***
+struct {
+  struct spinlock lock;
+  struct kmutex mutex[MAX_MUTEXES];
+} mutex;
+int nextmutex = 1;
+//end of our code***
+
 int nextpid = 1;
 extern void forkret(void);
 extern void trapret(void);
@@ -60,11 +70,35 @@ myproc(void) {
   struct proc *p;
   pushcli();
   c = mycpu();
-  p = c->proc;
+  //p = c->proc;
+  p = c->kthread->owner;
   popcli();
   return p;
 }
 
+//our code**********
+struct kthread*
+mykthread(){
+  struct cpu *c;
+  struct kthread *kt;
+  pushcli();
+  c = mycpu();
+  kt = c->kthread;
+  popcli();
+  return kt;
+}
+
+struct spinlock* 
+getptablelock(){
+  return &ptable.lock;
+}
+
+struct spinlock* 
+getmutexlock(){
+  return &mutex.lock;
+}
+//end of our code****
+
 //PAGEBREAK: 32
 // Look in the process table for an UNUSED proc.
 // If found, change state to EMBRYO and initialize
@@ -75,42 +109,68 @@ allocproc(void)
 {
   struct proc *p;
   char *sp;
+  int i = 0;
 
   acquire(&ptable.lock);
 
-  for(p = ptable.proc; p < &ptable.proc[NPROC]; p++)
-    if(p->state == UNUSED)
+  for(p = ptable.proc; p < &ptable.proc[NPROC]; p++){
+    if(p->pstate == UNUSED)
       goto found;
+    i++;
+  }
 
   release(&ptable.lock);
   return 0;
 
 found:
-  p->state = EMBRYO;
-  p->pid = nextpid++;
-
+  p->pstate = EMBRYO;
+  p->ppid = nextpid++;
+  p->runnablethreads = 0;
   release(&ptable.lock);
 
+  //our code******
+  //reset all threads. stack memory free is at wait()
+  for(i = 0 ; i < NTHREAD ; i++) {
+    p->kthreads[i].state = UNUSED;
+    p->kthreads[i].kstack = 0;
+    p->kthreads[i].kpid = 0;
+    p->kthreads[i].owner = 0;
+    p->kthreads[i].context = 0;
+    p->kthreads[i].tf = 0;
+    p->kthreads[i].killed = 0;
+    p->kthreads[i].name[0] = 0;
+    p->kthreads[i].kchan = 0;
+  }
+
+  p->indexinptable = i;
+  struct kthread *t = &(p->kthreads[0]);
+  t->owner = p;
+  t->state = EMBRYO;
+  t->kpid = nextpid++;
+  //add name for debug
+
+  //end of our code***
+
   // Allocate kernel stack.
-  if((p->kstack = kalloc()) == 0){
-    p->state = UNUSED;
+  if((t->kstack = kalloc()) == 0){
+    p->pstate = UNUSED;
     return 0;
   }
-  sp = p->kstack + KSTACKSIZE;
+  sp = t->kstack + KSTACKSIZE;
 
   // Leave room for trap frame.
-  sp -= sizeof *p->tf;
-  p->tf = (struct trapframe*)sp;
+  sp -= sizeof *t->tf;
+  t->tf = (struct trapframe*)sp;
 
   // Set up new context to start executing at forkret,
   // which returns to trapret.
   sp -= 4;
   *(uint*)sp = (uint)trapret;
 
-  sp -= sizeof *p->context;
-  p->context = (struct context*)sp;
-  memset(p->context, 0, sizeof *p->context);
-  p->context->eip = (uint)forkret;
+  sp -= sizeof *t->context;
+  t->context = (struct context*)sp;
+  memset(t->context, 0, sizeof *t->context);
+  t->context->eip = (uint)forkret;
 
   return p;
 }
@@ -121,25 +181,26 @@ void
 userinit(void)
 {
   struct proc *p;
+  struct kthread *t;
   extern char _binary_initcode_start[], _binary_initcode_size[];
 
   p = allocproc();
-  
+  t = &(p->kthreads[0]);
   initproc = p;
   if((p->pgdir = setupkvm()) == 0)
     panic("userinit: out of memory?");
   inituvm(p->pgdir, _binary_initcode_start, (int)_binary_initcode_size);
   p->sz = PGSIZE;
-  memset(p->tf, 0, sizeof(*p->tf));
-  p->tf->cs = (SEG_UCODE << 3) | DPL_USER;
-  p->tf->ds = (SEG_UDATA << 3) | DPL_USER;
-  p->tf->es = p->tf->ds;
-  p->tf->ss = p->tf->ds;
-  p->tf->eflags = FL_IF;
-  p->tf->esp = PGSIZE;
-  p->tf->eip = 0;  // beginning of initcode.S
-
-  safestrcpy(p->name, "initcode", sizeof(p->name));
+  memset(t->tf, 0, sizeof(*t->tf));
+  t->tf->cs = (SEG_UCODE << 3) | DPL_USER;
+  t->tf->ds = (SEG_UDATA << 3) | DPL_USER;
+  t->tf->es = t->tf->ds;
+  t->tf->ss = t->tf->ds;
+  t->tf->eflags = FL_IF;
+  t->tf->esp = PGSIZE;
+  t->tf->eip = 0;  // beginning of initcode.S
+
+  safestrcpy(p->pname, "initcode", sizeof(p->pname));
   p->cwd = namei("/");
 
   // this assignment to p->state lets other cores
@@ -148,7 +209,9 @@ userinit(void)
   // because the assignment might not be atomic.
   acquire(&ptable.lock);
 
-  p->state = RUNNABLE;
+  p->pstate = RUNNABLE;
+  t->state = RUNNABLE;
+  p->runnablethreads++;
 
   release(&ptable.lock);
 }
@@ -158,19 +221,25 @@ userinit(void)
 int
 growproc(int n)
 {
+  acquire(&ptable.lock);  //needs to hold ptable lock for pipe maybe?
   uint sz;
   struct proc *curproc = myproc();
 
   sz = curproc->sz;
   if(n > 0){
-    if((sz = allocuvm(curproc->pgdir, sz, sz + n)) == 0)
+    if((sz = allocuvm(curproc->pgdir, sz, sz + n)) == 0){
+      release(&ptable.lock);
       return -1;
+    }
   } else if(n < 0){
-    if((sz = deallocuvm(curproc->pgdir, sz, sz + n)) == 0)
+    if((sz = deallocuvm(curproc->pgdir, sz, sz + n)) == 0){
+      release(&ptable.lock);
       return -1;
+    }
   }
   curproc->sz = sz;
-  switchuvm(curproc);
+  switchuvm(curproc, mykthread());
+  release(&ptable.lock);
   return 0;
 }
 
@@ -183,53 +252,77 @@ fork(void)
   int i, pid;
   struct proc *np;
   struct proc *curproc = myproc();
+  struct kthread *curthread = mykthread();
 
   // Allocate process.
   if((np = allocproc()) == 0){
     return -1;
   }
-
+  acquire(&ptable.lock);
   // Copy process state from proc.
   if((np->pgdir = copyuvm(curproc->pgdir, curproc->sz)) == 0){
-    kfree(np->kstack);
-    np->kstack = 0;
-    np->state = UNUSED;
+    kfree(np->kthreads[0].kstack);
+    np->kthreads[0].kstack = 0;
+    np->kthreads[0].state = UNUSED;
+    np->pstate = UNUSED;
+    release(&ptable.lock);
     return -1;
   }
   np->sz = curproc->sz;
-  np->parent = curproc;
-  *np->tf = *curproc->tf;
-
+  np->pparent = curproc;
+  *(np->kthreads[0].tf) = *(curthread->tf); //modified
   // Clear %eax so that fork returns 0 in the child.
-  np->tf->eax = 0;
+  np->kthreads[0].tf->eax = 0;
 
   for(i = 0; i < NOFILE; i++)
     if(curproc->ofile[i])
       np->ofile[i] = filedup(curproc->ofile[i]);
   np->cwd = idup(curproc->cwd);
 
-  safestrcpy(np->name, curproc->name, sizeof(curproc->name));
-
-  pid = np->pid;
+  safestrcpy(np->pname, curproc->pname, sizeof(curproc->pname));
 
-  acquire(&ptable.lock);
+  pid = np->ppid;
 
-  np->state = RUNNABLE;
+  np->pstate = RUNNABLE;
+  //our code***
+  np->kthreads[0].state = RUNNABLE;
+  np->runnablethreads++;
+  //end of our code***
 
   release(&ptable.lock);
 
   return pid;
 }
 
-// Exit the current process.  Does not return.
-// An exited process remains in the zombie state
-// until its parent calls wait() to find out it exited.
+//called by the last thread of a process that performs exit.
 void
-exit(void)
-{
-  struct proc *curproc = myproc();
-  struct proc *p;
+exitproc(){
   int fd;
+  struct proc *p;
+  struct kthread *t;
+  struct kthread *curthread = mykthread();
+  struct proc *curproc = myproc();
+
+  for(t = curproc->kthreads; t < &curproc->kthreads[NTHREAD]; t++){
+    if(t->kpid == curthread->kpid) {
+      continue;
+    }
+    if (!(t->state == ZOMBIE || t->state == UNUSED)){
+      panic("exitproc is called but not all other threads are dead!");
+    }
+    else if(t->state == ZOMBIE) {
+      kfree(t->kstack);
+      t->kpid = 0;
+      t->owner = 0;
+      t->context = 0;
+      t->tf = 0;
+      t->killed = 0;
+      t->name[0] = 0;
+      t->state = UNUSED;
+    }
+  }
+
+  deallocallprocessmutexs();
 
   if(curproc == initproc)
     panic("init exiting");
@@ -250,23 +343,68 @@ exit(void)
   acquire(&ptable.lock);
 
   // Parent might be sleeping in wait().
-  wakeup1(curproc->parent);
+  wakeup1(curproc->pparent);
+  //our code***
+  wakeup1(curthread->kchan);
+  //end of our code***
 
   // Pass abandoned children to init.
   for(p = ptable.proc; p < &ptable.proc[NPROC]; p++){
-    if(p->parent == curproc){
-      p->parent = initproc;
-      if(p->state == ZOMBIE)
+    if(p->pparent == curproc){
+      p->pparent = initproc;
+      if(p->pstate == ZOMBIE)
         wakeup1(initproc);
     }
   }
 
   // Jump into the scheduler, never to return.
-  curproc->state = ZOMBIE;
+  //our code***
+  curthread->state = ZOMBIE;
+  //end of our code***
+  curproc->pstate = ZOMBIE;
   sched();
   panic("zombie exit");
 }
 
+// Exit the current process.  Does not return.
+// An exited process remains in the zombie state
+// until its parent calls wait() to find out it exited.
+void
+exit(void)
+{
+  struct kthread *curthread = mykthread();
+  struct proc *curproc = curthread->owner;
+  struct kthread *t;
+  int last = 1;
+  //set all threads kill field and check if last thread of the process
+  acquire(&ptable.lock);
+  for(t = curproc->kthreads; t < &curproc->kthreads[NTHREAD]; t++){
+    t->killed = 1;
+    if(t->state == SLEEPING){
+      t->state = RUNNABLE;
+      curproc->pstate = RUNNABLE;
+      curproc->runnablethreads++;
+    }
+    if (t->kpid != curthread->kpid && !(t->state == ZOMBIE || t->state == UNUSED)){
+      last = 0;
+    }
+  }
+
+  if (last){
+    //not returning from this call
+    release(&ptable.lock);
+    exitproc();
+  }
+  else{
+    //thread will not run again
+    curthread->state = ZOMBIE;
+    wakeup1(curthread);
+  }
+  sched();
+  panic("not supposed to be here!\n");
+  release(&ptable.lock);
+}
+
 // Wait for a child process to exit and return its pid.
 // Return -1 if this process has no children.
 int
@@ -275,33 +413,47 @@ wait(void)
   struct proc *p;
   int havekids, pid;
   struct proc *curproc = myproc();
+  struct kthread *t;
   
   acquire(&ptable.lock);
   for(;;){
     // Scan through table looking for exited children.
     havekids = 0;
     for(p = ptable.proc; p < &ptable.proc[NPROC]; p++){
-      if(p->parent != curproc)
+      if(p->pparent != curproc)
         continue;
       havekids = 1;
-      if(p->state == ZOMBIE){
+      if(p->pstate == ZOMBIE){
         // Found one.
-        pid = p->pid;
-        kfree(p->kstack);
-        p->kstack = 0;
+        pid = p->ppid;
+        //our code***
+        for(t = curproc->kthreads; t < &curproc->kthreads[NTHREAD]; t++){
+          if (t->state == ZOMBIE){
+            kfree(t->kstack);
+            t->kstack = 0;
+            t->state = UNUSED;
+            t->kpid = -1; //for debug
+            //no need for wakeup(t->chan) because process is zombie
+          }
+        }
+        //end of our code***
+
+        //kfree(p->kstack);
+        //p->kstack = 0;
         freevm(p->pgdir);
-        p->pid = 0;
-        p->parent = 0;
-        p->name[0] = 0;
-        p->killed = 0;
-        p->state = UNUSED;
+        p->ppid = 0;
+        p->pparent = 0;
+        p->pname[0] = 0;
+        p->pstate = UNUSED;
+        p->runnablethreads = 0;
         release(&ptable.lock);
         return pid;
       }
     }
 
     // No point waiting if we don't have any children.
-    if(!havekids || curproc->killed){
+    if(!havekids){
+    //if(!havekids || curproc->killed){
       release(&ptable.lock);
       return -1;
     }
@@ -324,7 +476,9 @@ scheduler(void)
 {
   struct proc *p;
   struct cpu *c = mycpu();
-  c->proc = 0;
+  struct kthread *t;
+  int found = 0;
+  //c->proc = 0;
   
   for(;;){
     // Enable interrupts on this processor.
@@ -332,23 +486,37 @@ scheduler(void)
 
     // Loop over process table looking for process to run.
     acquire(&ptable.lock);
+    found = 0;
     for(p = ptable.proc; p < &ptable.proc[NPROC]; p++){
-      if(p->state != RUNNABLE)
+      if(p->pstate != RUNNABLE)
         continue;
+    
+      for(t = p->kthreads; t < &p->kthreads[NTHREAD]; t++){
+        if(t->state == RUNNABLE){
+          found = 1;
+          break;
+        }
+      }
+      if(!found)
+        panic("no runnable thread found in runnable process");
+
 
       // Switch to chosen process.  It is the process's job
       // to release ptable.lock and then reacquire it
       // before jumping back to us.
-      c->proc = p;
-      switchuvm(p);
-      p->state = RUNNING;
-
-      swtch(&(c->scheduler), p->context);
+      c->kthread = t;
+      switchuvm(p, t);
+      t->state = RUNNING;
+      p->runnablethreads--;
+      if(p->runnablethreads == 0)
+        p->pstate = RUNNING;
+
+      swtch(&(c->scheduler), t->context);
       switchkvm();
 
       // Process is done running for now.
       // It should have changed its p->state before coming back.
-      c->proc = 0;
+      c->kthread = 0;
     }
     release(&ptable.lock);
 
@@ -366,18 +534,19 @@ void
 sched(void)
 {
   int intena;
-  struct proc *p = myproc();
+  //struct proc *p = myproc();
+  struct kthread *t = mykthread();
 
   if(!holding(&ptable.lock))
     panic("sched ptable.lock");
   if(mycpu()->ncli != 1)
     panic("sched locks");
-  if(p->state == RUNNING)
+  if(t->state == RUNNING)
     panic("sched running");
   if(readeflags()&FL_IF)
     panic("sched interruptible");
   intena = mycpu()->intena;
-  swtch(&p->context, mycpu()->scheduler);
+  swtch(&t->context, mycpu()->scheduler);
   mycpu()->intena = intena;
 }
 
@@ -386,7 +555,9 @@ void
 yield(void)
 {
   acquire(&ptable.lock);  //DOC: yieldlock
-  myproc()->state = RUNNABLE;
+  mykthread()->state = RUNNABLE;
+  mykthread()->owner->pstate = RUNNABLE;
+  mykthread()->owner->runnablethreads++;
   sched();
   release(&ptable.lock);
 }
@@ -417,9 +588,10 @@ forkret(void)
 void
 sleep(void *chan, struct spinlock *lk)
 {
-  struct proc *p = myproc();
+  //struct proc *p = myproc();
+  struct kthread *t = mykthread();
   
-  if(p == 0)
+  if(t == 0)
     panic("sleep");
 
   if(lk == 0)
@@ -436,13 +608,13 @@ sleep(void *chan, struct spinlock *lk)
     release(lk);
   }
   // Go to sleep.
-  p->chan = chan;
-  p->state = SLEEPING;
+  t->kchan = chan;
+  t->state = SLEEPING;
 
   sched();
 
   // Tidy up.
-  p->chan = 0;
+  t->kchan = 0;
 
   // Reacquire original lock.
   if(lk != &ptable.lock){  //DOC: sleeplock2
@@ -458,10 +630,17 @@ static void
 wakeup1(void *chan)
 {
   struct proc *p;
+  struct kthread *t;
 
-  for(p = ptable.proc; p < &ptable.proc[NPROC]; p++)
-    if(p->state == SLEEPING && p->chan == chan)
-      p->state = RUNNABLE;
+  for(p = ptable.proc; p < &ptable.proc[NPROC]; p++){
+    for(t = p->kthreads; t < &p->kthreads[NTHREAD]; t++){
+      if(t->state == SLEEPING && t->kchan == chan){
+        t->state = RUNNABLE;
+        p->runnablethreads++;
+        p->pstate = RUNNABLE;
+      }
+    }
+  }
 }
 
 // Wake up all processes sleeping on chan.
@@ -480,14 +659,19 @@ int
 kill(int pid)
 {
   struct proc *p;
+  struct kthread *t;
 
   acquire(&ptable.lock);
   for(p = ptable.proc; p < &ptable.proc[NPROC]; p++){
-    if(p->pid == pid){
-      p->killed = 1;
-      // Wake process from sleep if necessary.
-      if(p->state == SLEEPING)
-        p->state = RUNNABLE;
+    if(p->ppid == pid){
+      for(t = p->kthreads; t < &p->kthreads[NTHREAD]; t++){
+        t->killed = 1;
+        if(t->state == SLEEPING){
+          t->state = RUNNABLE;
+          p->pstate = RUNNABLE;
+          p->runnablethreads++;
+        }
+      }
       release(&ptable.lock);
       return 0;
     }
@@ -496,6 +680,247 @@ kill(int pid)
   return -1;
 }
 
+int kthread_create(void (*start_func)(), void* stack){
+  struct proc *curproc = myproc();
+  struct kthread *t;
+  int found = 0;
+
+  acquire(&ptable.lock);
+  for(t = curproc->kthreads; t < &curproc->kthreads[NTHREAD]; t++){
+    if(t->state == UNUSED){
+      found = 1;
+      break;
+    }
+  }
+  if(!found){
+    release(&ptable.lock);
+    return -1;
+  }
+
+  // Allocate kernel stack.
+  if((t->kstack = kalloc()) == 0){
+    t->state = UNUSED;
+    release(&ptable.lock);
+    return -1;
+  }
+  t->kpid = nextpid++;
+  t->owner = curproc;
+  t->killed = 0;
+  t->name[0] = 0;
+  t->state = EMBRYO;
+  
+  //our code***
+  char *sp = t->kstack + KSTACKSIZE;
+
+  // Leave room for trap frame.
+  sp -= sizeof *t->tf;
+  t->tf = (struct trapframe*)sp;
+  memset(t->tf, 0, sizeof(*t->tf));
+  *(t->tf) = *(mykthread()->tf);
+
+  //setup trapframe
+  t->tf->eip = (uint)start_func;
+  t->tf->ebp = (uint)stack;
+  t->tf->esp = (uint)stack;
+  t->tf->eax = 0;
+
+  // Set up new context to start executing at forkret,
+  // which returns to trapret.
+  sp -= 4;
+  *(uint*)sp = (uint)trapret;
+
+  sp -= sizeof *t->context;
+  t->context = (struct context*)sp;
+  memset(t->context, 0, sizeof *t->context);
+  t->context->eip = (uint)forkret;
+
+  t->state = RUNNABLE;
+  t->owner->pstate = RUNNABLE;
+  t->owner->runnablethreads++;
+
+  release(&ptable.lock);
+  return t->kpid;
+  //end of our code***
+}
+int kthread_id(){
+  return mykthread()->kpid;
+}
+void kthread_exit(){
+  struct proc *curproc = myproc();
+  struct kthread *t;
+  struct kthread *curthread = mykthread();
+  int last = 1;
+
+  acquire(&ptable.lock); 
+  for(t = curproc->kthreads; t < &curproc->kthreads[NTHREAD]; t++){
+    if(t->kpid == curthread->kpid || t->state == UNUSED || t->state == ZOMBIE) {
+      continue;
+    }
+    last = 0;
+  }
+
+  if(!last) {
+    curthread->state = ZOMBIE;
+    wakeup1(curthread);
+    
+    sched();
+    panic("at exit thread, not supposed to be here!\n");
+    release(&ptable.lock);
+
+    return;
+  }
+
+  else {
+    release(&ptable.lock);
+    exitproc();
+  }
+}
+int kthread_join(int thread_id){
+  struct proc *curproc = myproc();
+  struct kthread *t;
+
+  if(mykthread()->kpid == thread_id)
+    panic("join on calling thread\n");
+    
+  acquire(&ptable.lock);
+  if(mykthread()->killed){
+    release(&ptable.lock);
+    kthread_exit();
+  }
+  for(t = curproc->kthreads; t < &curproc->kthreads[NTHREAD]; t++){
+    if(t->kpid != thread_id)
+      continue;
+    if(t->state != ZOMBIE){
+      sleep(t, &ptable.lock);
+    }
+
+    if(t->state != ZOMBIE){
+      release(&ptable.lock);
+      return kthread_join(thread_id);
+    }
+
+    kfree(t->kstack);
+    t->kpid = 0;
+    t->owner = 0;
+    t->context = 0;
+    t->tf = 0;
+    t->killed = 0;
+    t->name[0] = 0;
+    t->state = UNUSED;
+    release(&ptable.lock);
+    return 0;
+    
+  }
+  release(&ptable.lock);
+  return -1;
+}
+
+int kthread_mutex_alloc(){
+  struct kmutex* m;
+  acquire(&mutex.lock);
+  for(m = mutex.mutex; m < &mutex.mutex[MAX_MUTEXES]; m++){
+    if(m->id == 0){
+      m->id = nextmutex++;
+      m->locked = 0;
+      m->creator = myproc()->ppid;
+      release(&mutex.lock);
+      return m->id;
+    }
+  }
+  //no free mutex is available
+  release(&mutex.lock);
+  return -1;
+}
+
+//dealloc all process mutexts even if mutex is locked
+void deallocallprocessmutexs() {
+  struct kmutex *m;
+  acquire(&mutex.lock);
+  for(m = mutex.mutex; m < &mutex.mutex[MAX_MUTEXES]; m++){
+    if(m->creator == myproc()->ppid){
+      m->id = 0;
+      m->locked = 0;
+      m->lockingkthread = 0;
+      m->creator = 0;
+    }
+  }
+  release(&mutex.lock);
+}
+
+int kthread_mutex_dealloc(int mutex_id){
+  struct kmutex* m;
+  acquire(&mutex.lock);
+  for(m = mutex.mutex; m < &mutex.mutex[MAX_MUTEXES]; m++){
+    if(m->id == mutex_id && !(m->locked)){
+      m->id = 0;
+      m->lockingkthread = 0;
+      m->creator = 0;
+      release(&mutex.lock);
+      return 0;
+    }
+  }
+  //no such mutex id or mutex is locked
+  release(&mutex.lock);
+  return -1;
+}
+
+int kthread_mutex_lock(int mutex_id){
+  struct kmutex* m;
+  struct kthread* curthread = mykthread();
+entry:
+  acquire(&mutex.lock);
+  for(m = mutex.mutex; m < &mutex.mutex[MAX_MUTEXES]; m++){
+    if(m->id == mutex_id){
+      if(!m->locked){
+        //lock the mutex
+        m->locked = 1;
+        m->lockingkthread = curthread->kpid;
+        release(&mutex.lock);
+        return 0;
+      }
+      else{
+        if(m->lockingkthread == curthread->kpid){
+          release(&mutex.lock);
+          return -1;
+        }
+        //go into BLOCKED state
+        curthread->state = SLEEPING;
+        curthread->kchan = m;
+        release(&mutex.lock);
+        acquire(&ptable.lock);
+        sched();
+        //woken up from waiting for mutex
+        release(&ptable.lock);
+        curthread->kchan = 0;
+        goto entry;
+      }
+    }
+  }
+  //no such mutex id or mutex is locked
+  release(&mutex.lock);
+  return -1;
+}
+
+int kthread_mutex_unlock(int mutex_id){
+  struct kmutex* m;
+  struct kthread* curthread = mykthread();
+  acquire(&mutex.lock);
+  for(m = mutex.mutex; m < &mutex.mutex[MAX_MUTEXES]; m++){
+    if(m->id == mutex_id && m->lockingkthread == curthread->kpid && m->locked){
+      //unlock the mutex
+      m->locked = 0;
+      m->lockingkthread = 0;
+      //wakeup sleeping threads
+      wakeup(m);
+      release(&mutex.lock);
+      return 0;
+    }
+  }
+  release(&mutex.lock);
+  return -1;
+}
+
+
 //PAGEBREAK: 36
 // Print a process listing to console.  For debugging.
 // Runs when user types ^P on console.
@@ -517,15 +942,15 @@ procdump(void)
   uint pc[10];
 
   for(p = ptable.proc; p < &ptable.proc[NPROC]; p++){
-    if(p->state == UNUSED)
+    if(p->pstate == UNUSED)
       continue;
-    if(p->state >= 0 && p->state < NELEM(states) && states[p->state])
-      state = states[p->state];
+    if(p->pstate >= 0 && p->pstate < NELEM(states) && states[p->pstate])
+      state = states[p->pstate];
     else
       state = "???";
-    cprintf("%d %s %s", p->pid, state, p->name);
-    if(p->state == SLEEPING){
-      getcallerpcs((uint*)p->context->ebp+2, pc);
+    cprintf("%d %s %s", p->ppid, state, p->pname);
+    if(p->pstate == SLEEPING){
+      getcallerpcs((uint*)mykthread()->context->ebp+2, pc);
       for(i=0; i<10 && pc[i] != 0; i++)
         cprintf(" %p", pc[i]);
     }
diff --git a/proc.h b/proc.h
index 1647114..53867d4 100644
--- a/proc.h
+++ b/proc.h
@@ -1,3 +1,5 @@
+#define NTHREAD 16
+
 // Per-CPU state
 struct cpu {
   uchar apicid;                // Local APIC ID
@@ -7,7 +9,8 @@ struct cpu {
   volatile uint started;       // Has the CPU started?
   int ncli;                    // Depth of pushcli nesting.
   int intena;                  // Were interrupts enabled before pushcli?
-  struct proc *proc;           // The process running on this cpu or null
+  //struct proc *proc;           // The process running on this cpu or null
+  struct kthread *kthread;     // the kthread running on this cpu or null
 };
 
 extern struct cpu cpus[NCPU];
@@ -34,21 +37,44 @@ struct context {
 
 enum procstate { UNUSED, EMBRYO, SLEEPING, RUNNABLE, RUNNING, ZOMBIE };
 
+struct kthread{
+  char *kstack;                // Bottom of kernel stack for this kthread
+  enum procstate state;        // Kthread state
+  int kpid;                     // Kthread ID
+  struct proc *owner;          // Parent process
+  struct trapframe *tf;        // Trap frame for current syscall
+  struct context *context;     // swtch() here to run Kthread
+  void *kchan;                  // If non-zero, sleeping on chan
+  int killed;                  // If non-zero, have been killed
+  char name[16];               // Kthread name (debugging)
+};
+
+struct kmutex{
+  int id;
+  uint locked;
+  int lockingkthread;
+  int creator;
+};
+
+
 // Per-process state
 struct proc {
   uint sz;                     // Size of process memory (bytes)
   pde_t* pgdir;                // Page table
-  char *kstack;                // Bottom of kernel stack for this process
-  enum procstate state;        // Process state
-  int pid;                     // Process ID
-  struct proc *parent;         // Parent process
-  struct trapframe *tf;        // Trap frame for current syscall
-  struct context *context;     // swtch() here to run process
-  void *chan;                  // If non-zero, sleeping on chan
-  int killed;                  // If non-zero, have been killed
+  //char *kstack;                // Bottom of kernel stack for this process
+  enum procstate pstate;        // Process state
+  int ppid;                     // Process ID
+  struct proc *pparent;         // Parent process
+  //struct trapframe *tf;        // Trap frame for current syscall
+  //struct context *context;     // swtch() here to run process
+  void *pchan;                  // If non-zero, sleeping on chan
+  //int killed;                  // If non-zero, have been killed
   struct file *ofile[NOFILE];  // Open files
   struct inode *cwd;           // Current directory
-  char name[16];               // Process name (debugging)
+  char pname[16];               // Process name (debugging)
+  struct kthread kthreads[NTHREAD]; //process's kthreads
+  int runnablethreads;
+  int indexinptable;
 };
 
 // Process memory is laid out contiguously, low addresses first:
diff --git a/sanity.c b/sanity.c
new file mode 100644
index 0000000..ec88147
--- /dev/null
+++ b/sanity.c
@@ -0,0 +1,275 @@
+#include "param.h"
+#include "types.h"
+#include "stat.h"
+#include "user.h"
+#include "fs.h"
+#include "fcntl.h"
+#include "syscall.h"
+#include "traps.h"
+#include "memlayout.h"
+#include "tournament_tree.h"
+#include "kthread.h"
+
+int stdout = 1;
+int globalinteger, globalmutexid;
+
+//globals for advance tree test
+  trnmnt_tree *tree;
+  struct kthread *threads[16];
+  int ids[16];
+  int holdexecution = 1;
+//
+
+void* allocstack(){
+  void* stack = malloc(MAX_STACK_SIZE);
+  stack = stack + MAX_STACK_SIZE;
+  return stack;
+}
+
+void func0(){
+  kthread_exit();
+}
+
+void func1(){
+  sleep(50);
+  int i = 3;
+  int ii = 33;
+  int iii = 333;
+  globalinteger = globalinteger * globalinteger;
+  globalinteger += (i + ii + iii);
+  globalinteger -= (i + ii + iii);
+
+  kthread_exit();
+}
+
+void func2(){
+  sleep(1000);
+  kthread_exit();
+}
+
+void func3(){
+  int i, found;
+  int id = 0;
+  for(i = 0; i < 16; i++){
+    if(ids[i] == kthread_id()){
+      found = 1;
+      id = i;
+    }
+  }
+  if(!found){
+    printf(1, "error with func3 id\n");
+    kthread_exit();
+  }
+  while(holdexecution){}
+  sleep((id * 991 * 223) % 500);
+  if(trnmnt_tree_acquire(tree, id) == -1){
+    printf(1, "error with tree acquire\n");
+    kthread_exit();
+  }
+
+  printf(1, "this text from ID: %d should be readable\n", id);
+
+  if(trnmnt_tree_release(tree, id) == -1){
+    printf(1, "error with tree release\n");
+    kthread_exit();
+  }
+  kthread_exit();
+}
+
+int
+kthreadcreate(){
+  void *dellocs[16];
+  int i, thread_id = 0;
+  void (*fun_ptr)() = &func0;
+  void *stack;
+  for (i = 0; i < 15; i++){
+    stack = allocstack();
+    dellocs[i] = stack;
+    thread_id = kthread_create(fun_ptr, stack);
+    sleep(10);
+    if(thread_id < 0){
+      while(i > -1)
+        free(dellocs[i--]);
+      return 0;
+    }
+  }
+  i--;
+  stack = allocstack();
+  thread_id = kthread_create(fun_ptr, stack);
+  if(thread_id != -1){
+    while(i > -1)
+      free(dellocs[i--]);
+    return 0;
+  }
+  sleep(10);
+  while(i > -1)
+    free(dellocs[i--]);
+  return 1;
+}
+
+int kthreadjoin(){
+  int thread_id;
+  void (*fun_ptr)() = &func1;
+  void *stack = allocstack();
+  globalinteger = 2;
+  thread_id = kthread_create(fun_ptr, stack);
+  kthread_join(thread_id);
+  free(stack);
+  globalinteger = globalinteger + globalinteger;
+  if(globalinteger == 8)
+    return 1;
+  if(globalinteger == 16)
+    return 0;
+  return 0;
+}
+
+void aqumutex(){
+  kthread_mutex_lock(globalmutexid);
+  globalinteger = 2;
+  kthread_mutex_unlock(globalmutexid);
+  kthread_exit();
+}
+
+void releasemutex(){
+  if(kthread_mutex_unlock(globalmutexid) != -1)
+    globalinteger = 2;
+  kthread_exit();
+}
+
+int basicmutex(){
+  int threadid;
+  void (*fun_ptr)() = &aqumutex;
+  globalinteger = 1;
+  globalmutexid = kthread_mutex_alloc();
+  if(kthread_mutex_lock(globalmutexid) == -1)
+    return 0;
+  void* stack = allocstack();
+  threadid = kthread_create(fun_ptr, stack);
+  sleep(100);
+  if(globalinteger != 1)
+    return 0;
+  kthread_mutex_unlock(globalmutexid);
+  kthread_join(threadid);
+  free(stack);
+  if(globalinteger != 2)
+    return 0;
+  if(kthread_mutex_dealloc(globalmutexid) == -1)
+    return 0;
+  return 1;
+}
+
+int moremutex(){
+  int mutexids[MAX_MUTEXES];
+  int i;
+  void (*fun_ptr)() = &releasemutex;
+  for(i = 0; i < MAX_MUTEXES; i++){
+    mutexids[i] = kthread_mutex_alloc();
+    if(mutexids[i] == -1)
+      return 0;
+  }
+  if(kthread_mutex_alloc() != -1)
+    return 0;
+  if(kthread_mutex_lock(-1) != -1)
+    return 0;
+  globalmutexid = mutexids[0];
+  globalinteger = 0;
+  if(kthread_mutex_lock(globalmutexid) == -1)
+    return 0;
+  i = kthread_create(fun_ptr, allocstack());
+  if(i < 0)
+    return 0;
+  kthread_join(i);
+  if(globalinteger == 2)
+    return 0;
+  if(kthread_mutex_unlock(-1) != -1)
+    return 0;
+  if(kthread_mutex_dealloc(globalmutexid) != -1)
+    return 0;
+  if(kthread_mutex_unlock(globalmutexid) == -1)
+    return 0;
+  if(kthread_mutex_dealloc(globalmutexid) == -1)
+    return 0;
+  for(i = 0; i < MAX_MUTEXES; i++){
+    kthread_mutex_unlock(mutexids[i]);
+    kthread_mutex_dealloc(mutexids[i]);
+  }
+  return 1;
+}
+
+int basictree(){
+  trnmnt_tree* tree = trnmnt_tree_alloc(2);
+  if(tree == 0)
+    return 0;
+  if(trnmnt_tree_acquire(tree, 1) == -1){
+    printf(1, "failed accuire\n");
+    return 0;
+  }
+  if(trnmnt_tree_release(tree, 1) == -1){
+    printf(1, "failed release\n");
+    return 0;
+  }
+  if(trnmnt_tree_dealloc(tree) == -1){
+    printf(1, "failed dealloc\n");
+    return 0;
+  }
+  return 1;
+}
+
+int advancetree(){
+  int i;
+  void *stacks[16];
+  void (*fun_ptr)() = &func3;
+
+  tree = trnmnt_tree_alloc(4);
+  if(tree == 0)
+    return 0;
+
+  for(i = 0; i < 16; i++){
+    stacks[i] = allocstack();
+    ids[i] = kthread_create(fun_ptr, stacks[i]);
+    if(ids[i] == 0){
+      printf(1, "error creating thread\n");
+      exit();
+    }
+  }
+  holdexecution = 0;
+  for(i = 0; i < 16; i++){
+    kthread_join(ids[i]);
+    free(stacks[i]);
+  }
+  if(trnmnt_tree_dealloc(tree) == -1)
+    return 0;
+  return 1;
+}
+
+
+int
+main(int argc, char *argv[])
+{
+  int pid, i;
+  int numberoftests = 6;
+  int (*test[])() = {&kthreadcreate, &kthreadjoin, &basicmutex, &moremutex, &basictree, &advancetree};
+  char* names[] = {"kthread create", "kthread join", "basic mutex", "more mutex", "basic tree", "adcance tree"};
+
+  printf(1, "sanity starting, main pid: %d\n", kthread_id());
+  for (i = 0; i < numberoftests; i++){
+    pid = fork();
+    if(pid){
+      wait();
+    }
+    else{
+      if(test[i]()){
+        printf(1, "%s passed\n", names[i]);
+        exit();
+      }
+      else{
+      printf(1, "%s failed\n", names[i]);
+      exit();
+      }
+    }
+  }
+
+  printf(1, "sanity done\n");
+  exit(); 
+  return -1;
+}
diff --git a/sleeplock.c b/sleeplock.c
index e0750ea..82e4969 100644
--- a/sleeplock.c
+++ b/sleeplock.c
@@ -27,7 +27,7 @@ acquiresleep(struct sleeplock *lk)
     sleep(lk, &lk->lk);
   }
   lk->locked = 1;
-  lk->pid = myproc()->pid;
+  lk->pid = mykthread()->kpid;
   release(&lk->lk);
 }
 
@@ -47,7 +47,7 @@ holdingsleep(struct sleeplock *lk)
   int r;
   
   acquire(&lk->lk);
-  r = lk->locked && (lk->pid == myproc()->pid);
+  r = lk->locked && (lk->pid == mykthread()->kpid);
   release(&lk->lk);
   return r;
 }
diff --git a/spinlock.c b/spinlock.c
index 4020186..68f5672 100644
--- a/spinlock.c
+++ b/spinlock.c
@@ -25,8 +25,10 @@ void
 acquire(struct spinlock *lk)
 {
   pushcli(); // disable interrupts to avoid deadlock.
-  if(holding(lk))
+  if(holding(lk)){
+    cprintf("%d misbihaved...\n", mykthread()->kpid);
     panic("acquire");
+    }
 
   // The xchg is atomic.
   while(xchg(&lk->locked, 1) != 0)
diff --git a/syscall.c b/syscall.c
index ee85261..a5fc6c0 100644
--- a/syscall.c
+++ b/syscall.c
@@ -49,7 +49,7 @@ fetchstr(uint addr, char **pp)
 int
 argint(int n, int *ip)
 {
-  return fetchint((myproc()->tf->esp) + 4 + 4*n, ip);
+  return fetchint((mykthread()->tf->esp) + 4 + 4*n, ip);
 }
 
 // Fetch the nth word-sized system call argument as a pointer
@@ -103,7 +103,17 @@ extern int sys_unlink(void);
 extern int sys_wait(void);
 extern int sys_write(void);
 extern int sys_uptime(void);
+//our code***
+extern int sys_kthread_create(void);
+extern int sys_kthread_id(void);
+extern int sys_kthread_exit(void);
+extern int sys_kthread_join(void);
 
+extern int sys_kthread_mutex_alloc(void);
+extern int sys_kthread_mutex_dealloc(void);
+extern int sys_kthread_mutex_lock(void);
+extern int sys_kthread_mutex_unlock(void);
+//end of our code***
 static int (*syscalls[])(void) = {
 [SYS_fork]    sys_fork,
 [SYS_exit]    sys_exit,
@@ -126,20 +136,29 @@ static int (*syscalls[])(void) = {
 [SYS_link]    sys_link,
 [SYS_mkdir]   sys_mkdir,
 [SYS_close]   sys_close,
+[SYS_kthread_create]   sys_kthread_create,
+[SYS_kthread_id]   sys_kthread_id,
+[SYS_kthread_exit]   sys_kthread_exit,
+[SYS_kthread_join]   sys_kthread_join,
+[SYS_kthread_mutex_alloc]   sys_kthread_mutex_alloc,
+[SYS_kthread_mutex_dealloc]   sys_kthread_mutex_dealloc,
+[SYS_kthread_mutex_lock]   sys_kthread_mutex_lock,
+[SYS_kthread_mutex_unlock]   sys_kthread_mutex_unlock,
 };
 
 void
 syscall(void)
 {
   int num;
-  struct proc *curproc = myproc();
+  //struct proc *curproc = myproc();
+  struct kthread *curthread = mykthread();
 
-  num = curproc->tf->eax;
+  num = curthread->tf->eax;
   if(num > 0 && num < NELEM(syscalls) && syscalls[num]) {
-    curproc->tf->eax = syscalls[num]();
+    curthread->tf->eax = syscalls[num]();
   } else {
     cprintf("%d %s: unknown sys call %d\n",
-            curproc->pid, curproc->name, num);
-    curproc->tf->eax = -1;
+            curthread->kpid, curthread->name, num);
+    curthread->tf->eax = -1;
   }
 }
diff --git a/syscall.h b/syscall.h
index bc5f356..0ca6584 100644
--- a/syscall.h
+++ b/syscall.h
@@ -20,3 +20,11 @@
 #define SYS_link   19
 #define SYS_mkdir  20
 #define SYS_close  21
+#define SYS_kthread_create  22
+#define SYS_kthread_id  23
+#define SYS_kthread_exit  24
+#define SYS_kthread_join  25
+#define SYS_kthread_mutex_alloc  26
+#define SYS_kthread_mutex_dealloc  27
+#define SYS_kthread_mutex_lock  28
+#define SYS_kthread_mutex_unlock  29
diff --git a/sysproc.c b/sysproc.c
index 0686d29..723b570 100644
--- a/sysproc.c
+++ b/sysproc.c
@@ -39,7 +39,7 @@ sys_kill(void)
 int
 sys_getpid(void)
 {
-  return myproc()->pid;
+  return mykthread()->kpid;
 }
 
 int
@@ -67,7 +67,7 @@ sys_sleep(void)
   acquire(&tickslock);
   ticks0 = ticks;
   while(ticks - ticks0 < n){
-    if(myproc()->killed){
+    if(mykthread()->killed){
       release(&tickslock);
       return -1;
     }
@@ -89,3 +89,51 @@ sys_uptime(void)
   release(&tickslock);
   return xticks;
 }
+
+int sys_kthread_create(void){
+  void *start_func;
+  void *stack;
+  if(argptr(0, (char**)(&start_func), sizeof(void*)) < 0)
+    return -1;
+  if(argint(1, (void*)(&stack)) < 0)
+    return -1;
+  return kthread_create(start_func, stack);
+}
+int sys_kthread_id(void){
+  return kthread_id();
+}
+int sys_kthread_exit(void){
+  kthread_exit();
+  return 0;
+}
+int sys_kthread_join(void){
+  int thread_id;
+  if(argint(0, &thread_id) < 0)
+    return -1;
+  return kthread_join(thread_id);
+}
+
+int sys_kthread_mutex_alloc(void){
+  return kthread_mutex_alloc();
+}
+
+int sys_kthread_mutex_dealloc(void){
+  int mutex_id;
+  if(argint(0, &mutex_id) < 0)
+    return -1;
+  return kthread_mutex_dealloc(mutex_id);
+}
+
+int sys_kthread_mutex_lock(void){
+  int mutex_id;
+  if(argint(0, &mutex_id) < 0)
+    return -1;
+  return kthread_mutex_lock(mutex_id);
+}
+
+int sys_kthread_mutex_unlock(void){
+  int mutex_id;
+  if(argint(0, &mutex_id) < 0)
+    return -1;
+  return kthread_mutex_unlock(mutex_id);
+}
diff --git a/tournament_tree.c b/tournament_tree.c
new file mode 100644
index 0000000..9e8fa8f
--- /dev/null
+++ b/tournament_tree.c
@@ -0,0 +1,192 @@
+#include "tournament_tree.h"
+#include "kthread.h"
+#include "types.h"
+#include "stat.h"
+#include "user.h"
+
+
+void resetactivethreads(trnmnt_tree *tree){
+  int i;
+  for(i = 0; i < 2 << (tree->depth - 1); i++)
+    tree->activethreads[i] = 0;
+}
+
+void resetbaselevel(trnmnt_tree *tree){
+  int i;
+  for(i = 0; i < MAX_MUTEXES; i++)
+    tree->baselevel[i] = 0;
+}
+
+int allocnodes(trnmnt_tree *tree, struct node *n, int depth){
+  if(depth){
+    n->leftchild = (struct node*)malloc(sizeof(struct node));
+    n->rightchild = (struct node*)malloc(sizeof(struct node));
+    if(n->leftchild == 0 || n->rightchild == 0)
+      return 0;
+
+    n->leftchild->mutexid = kthread_mutex_alloc();
+    n->rightchild->mutexid = kthread_mutex_alloc();
+    if(n->leftchild->mutexid < 0 || n->rightchild->mutexid < 0)
+      return 0;
+
+    n->leftchild->parent = n;
+    n->rightchild->parent = n;
+    
+    if(depth -1 == 0){
+      //base level nodes
+      n->leftchild->nodeid = tree->nodesindex++;
+      n->rightchild->nodeid = tree->nodesindex++;
+      tree->baselevel[n->leftchild->nodeid] = n->leftchild;
+      tree->baselevel[n->rightchild->nodeid] = n->rightchild;
+    }
+    return (allocnodes(tree, n->leftchild, depth-1) && allocnodes(tree, n->rightchild, depth-1));
+  }
+  return 1;
+}
+
+int dellocnodes(struct node *n){
+  int res0 = 0;
+  int res1 = 0;
+  int res2 = 0;
+  if(n){
+    res0 = dellocnodes(n->leftchild);
+    res1 = dellocnodes(n->rightchild);
+    res2 = kthread_mutex_dealloc(n->mutexid);
+    n->nodeid = 0;
+    n->mutexid = 0;
+    n->aquiredthreadid = 0;
+    n->parent = 0;
+    n->leftchild = 0;
+    n->rightchild = 0;
+    free(n);
+    if(res0 == -1 || res1 == -1 || res2 == -1)
+      return -1;
+    return 0;
+  }
+return 0;
+}
+
+trnmnt_tree* trnmnt_tree_alloc(int depth){
+  struct trnmnt_tree *tree; 
+  tree = malloc(sizeof(struct trnmnt_tree));
+  if(tree == 0)
+    return 0;
+  tree->root = malloc(sizeof(struct node));
+  if(tree->root == 0)
+    return 0;
+  tree->root->mutexid = kthread_mutex_alloc();
+  if(tree->root->mutexid < 0)
+    return 0;
+  tree->threadsmutex = kthread_mutex_alloc();
+  if(tree->threadsmutex < 0)
+    return 0;
+  tree->activethreads = malloc(sizeof(int) * (2 << (depth-1)));
+  if(tree->activethreads == 0)
+    return 0;
+
+  tree->depth = depth;
+  tree->nodesindex = 0;
+  resetactivethreads(tree);
+  resetbaselevel(tree);
+  if(depth == 1){
+    //root only tree
+    tree->baselevel[0] = tree->root;
+    tree->root->nodeid = tree->nodesindex++;
+    return tree;
+  }
+  else{
+    if(allocnodes(tree, tree->root, depth-1) == 0)
+      return 0;
+    return tree;
+  }
+}
+
+int trnmnt_tree_dealloc(trnmnt_tree* tree){
+  int i, res;
+  //check for wating threads in the tree
+  kthread_mutex_lock(tree->threadsmutex);
+  for(i = 0; i < 2 << (tree->depth - 1); i++){
+    if(tree->activethreads[i] == 1){
+      kthread_mutex_unlock(tree->threadsmutex);
+      return -1;
+    }
+  }
+  res = dellocnodes(tree->root);
+  kthread_mutex_unlock(tree->threadsmutex);
+
+  kthread_mutex_dealloc(tree->threadsmutex);
+  free(tree->activethreads);
+  free(tree);
+  return res;
+}
+
+int aquirelevelup(struct node *n, int ID){
+  if(kthread_mutex_lock(n->mutexid) == -1)
+    return -1;
+  n->aquiredthreadid = ID;
+  if(n->parent == 0)
+    return 1;
+  return aquirelevelup(n->parent, ID);
+}
+
+int trnmnt_tree_acquire(trnmnt_tree* tree,int ID){
+  kthread_mutex_lock(tree->threadsmutex);
+  tree->activethreads[ID] = 1;
+  kthread_mutex_unlock(tree->threadsmutex);
+  struct node *initialnode = tree->baselevel[ID / 2];
+  if(initialnode == 0)
+    return -1;
+  if(kthread_mutex_lock(initialnode->mutexid) == -1)
+    return -1;
+  initialnode->aquiredthreadid = ID;
+  if(initialnode->parent == 0)
+    return 1;
+  //not root node, continue climbing
+  return aquirelevelup(initialnode->parent, ID);
+}
+
+int realeseleveldown(struct node *n, int ID){
+  if(kthread_mutex_unlock(n->mutexid) == -1)
+    return -1;
+  if(n->leftchild && n->leftchild->aquiredthreadid == ID){
+    return realeseleveldown(n->leftchild, ID);
+  }
+  if(n->rightchild && n->rightchild->aquiredthreadid == ID){
+    return realeseleveldown(n->rightchild, ID);
+  }
+  //no children, release is done
+  return 1;
+}
+
+int trnmnt_tree_release(trnmnt_tree* tree, int ID){
+  struct node *root = tree->root;
+  if(root != 0 && root->aquiredthreadid != ID)
+    return -1;
+  if(root->leftchild && root->leftchild->aquiredthreadid == ID){
+    if(kthread_mutex_unlock(root->mutexid) == -1)
+      return -1;
+    if(realeseleveldown(root->leftchild, ID) == -1)
+      return -1;
+    kthread_mutex_lock(tree->threadsmutex);
+    tree->activethreads[ID] = 0;
+    kthread_mutex_unlock(tree->threadsmutex);
+    return 0;
+  }
+  if(root->rightchild && root->rightchild->aquiredthreadid == ID){
+    if(kthread_mutex_unlock(root->mutexid) == -1)
+      return -1;
+    if(realeseleveldown(root->rightchild, ID) == -1)
+      return -1;
+    kthread_mutex_lock(tree->threadsmutex);
+    tree->activethreads[ID] = 0;
+    kthread_mutex_unlock(tree->threadsmutex);
+    return 0;
+  }
+  //no children
+  if(kthread_mutex_unlock(root->mutexid) == -1)
+    return -1;
+  kthread_mutex_lock(tree->threadsmutex);
+  tree->activethreads[ID] = 0;
+  kthread_mutex_unlock(tree->threadsmutex);
+  return 0;
+}
diff --git a/tournament_tree.h b/tournament_tree.h
new file mode 100644
index 0000000..40c3d18
--- /dev/null
+++ b/tournament_tree.h
@@ -0,0 +1,19 @@
+#define MAX_MUTEXES 64
+
+typedef struct node {
+    int nodeid;
+    int mutexid;
+    int aquiredthreadid;
+    struct node *parent;
+    struct node *leftchild;
+    struct node *rightchild;
+} node;
+
+typedef struct trnmnt_tree{
+  int depth;
+  struct node *root;
+  struct node *baselevel[MAX_MUTEXES];
+  int *activethreads;
+  int threadsmutex;
+  int nodesindex;
+} trnmnt_tree;
diff --git a/trap.c b/trap.c
index 41c66eb..03ee855 100644
--- a/trap.c
+++ b/trap.c
@@ -37,12 +37,12 @@ void
 trap(struct trapframe *tf)
 {
   if(tf->trapno == T_SYSCALL){
-    if(myproc()->killed)
-      exit();
-    myproc()->tf = tf;
+    if(mykthread()->killed)
+      kthread_exit();
+    mykthread()->tf = tf;
     syscall();
-    if(myproc()->killed)
-      exit();
+    if(mykthread()->killed)
+      kthread_exit();
     return;
   }
 
@@ -80,7 +80,7 @@ trap(struct trapframe *tf)
 
   //PAGEBREAK: 13
   default:
-    if(myproc() == 0 || (tf->cs&3) == 0){
+    if(mykthread() == 0 || (tf->cs&3) == 0){
       // In kernel, it must be our mistake.
       cprintf("unexpected trap %d from cpu %d eip %x (cr2=0x%x)\n",
               tf->trapno, cpuid(), tf->eip, rcr2());
@@ -89,24 +89,24 @@ trap(struct trapframe *tf)
     // In user space, assume process misbehaved.
     cprintf("pid %d %s: trap %d err %d on cpu %d "
             "eip 0x%x addr 0x%x--kill proc\n",
-            myproc()->pid, myproc()->name, tf->trapno,
+            mykthread()->kpid, mykthread()->name, tf->trapno,
             tf->err, cpuid(), tf->eip, rcr2());
-    myproc()->killed = 1;
+    mykthread()->killed = 1;
   }
 
   // Force process exit if it has been killed and is in user space.
   // (If it is still executing in the kernel, let it keep running
   // until it gets to the regular system call return.)
-  if(myproc() && myproc()->killed && (tf->cs&3) == DPL_USER)
-    exit();
+  if(mykthread() && mykthread()->killed && (tf->cs&3) == DPL_USER)
+    kthread_exit();
 
   // Force process to give up CPU on clock tick.
   // If interrupts were on while locks held, would need to check nlock.
-  if(myproc() && myproc()->state == RUNNING &&
+  if(mykthread() && mykthread()->state == RUNNING &&
      tf->trapno == T_IRQ0+IRQ_TIMER)
     yield();
 
   // Check if the process has been killed since we yielded
-  if(myproc() && myproc()->killed && (tf->cs&3) == DPL_USER)
-    exit();
+  if(mykthread() && mykthread()->killed && (tf->cs&3) == DPL_USER)
+    kthread_exit();
 }
diff --git a/usys.S b/usys.S
index 8bfd8a1..cdc6687 100644
--- a/usys.S
+++ b/usys.S
@@ -29,3 +29,11 @@ SYSCALL(getpid)
 SYSCALL(sbrk)
 SYSCALL(sleep)
 SYSCALL(uptime)
+SYSCALL(kthread_create)
+SYSCALL(kthread_id)
+SYSCALL(kthread_exit)
+SYSCALL(kthread_join)
+SYSCALL(kthread_mutex_alloc)
+SYSCALL(kthread_mutex_dealloc)
+SYSCALL(kthread_mutex_lock)
+SYSCALL(kthread_mutex_unlock)
diff --git a/vm.c b/vm.c
index 7134cff..d6f2808 100644
--- a/vm.c
+++ b/vm.c
@@ -154,11 +154,13 @@ switchkvm(void)
 
 // Switch TSS and h/w page table to correspond to process p.
 void
-switchuvm(struct proc *p)
+switchuvm(struct proc *p, struct kthread *t)
 {
   if(p == 0)
     panic("switchuvm: no process");
-  if(p->kstack == 0)
+  if(t == 0)
+    panic("switchuvm: no kthread");
+  if(t->kstack == 0)
     panic("switchuvm: no kstack");
   if(p->pgdir == 0)
     panic("switchuvm: no pgdir");
@@ -168,7 +170,7 @@ switchuvm(struct proc *p)
                                 sizeof(mycpu()->ts)-1, 0);
   mycpu()->gdt[SEG_TSS].s = 0;
   mycpu()->ts.ss0 = SEG_KDATA << 3;
-  mycpu()->ts.esp0 = (uint)p->kstack + KSTACKSIZE;
+  mycpu()->ts.esp0 = (uint)(t->kstack + KSTACKSIZE);
   // setting IOPL=0 in eflags *and* iomb beyond the tss segment limit
   // forbids I/O instructions (e.g., inb and outb) from user space
   mycpu()->ts.iomb = (ushort) 0xFFFF;
